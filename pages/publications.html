<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Your Name</title>
    <link rel="stylesheet" href="../assets/css/style.css">
</head>
<body>
    <nav>
        <div class="nav-container">
            <a href="../index.html" class="nav-name">Your Name</a>
            <div class="nav-links">
                <a href="research.html">Research</a>
                <a href="publications.html" class="active">Publications</a>
                <a href="teaching.html">Teaching</a>
                <a href="talks.html">Talks</a>
                <a href="positions.html">Positions</a>
                <a href="contact.html">Contact</a>
            </div>
        </div>
    </nav>

    <header class="page-header">
        <div class="container">
            <h1 class="page-title">Publications</h1>
            <p class="page-description">
                A collection of my published research work, including journal articles, 
                conference papers, and preprints. Each publication includes a graphical 
                abstract and key findings.
            </p>
        </div>
    </header>

    <main class="container">
        <section class="filter-section">
            <div class="filter-buttons">
                <button class="filter-button active" data-filter="all">All Publications</button>
                <button class="filter-button" data-filter="journal">Journal Articles</button>
                <button class="filter-button" data-filter="conference">Conference Papers</button>
                <button class="filter-button" data-filter="preprint">Preprints</button>
            </div>
        </section>

        <section class="publications-grid">

            <!-- Publication 4 -->
            <article class="publication-card" data-type="preprint">
                <div class="publication-content">
                    <span class="publication-year">2024</span>
                    <h2 class="publication-title" >
                        Novae: a graph-based foundation model for spatial transcriptomics data
                    </h2>
                    <p class="publication-authors">
                        Quentin Blampey, <span class="publication-highlight">Hakim Benkirane</span>, 
                        Nadege Bercovici, Fabrice André, Paul-Henry Cournede
                    </p>
                    <p class="publication-journal">
                        Preprint on bioRxiv
                    </p>
                    <p class="publication-abstract">
                        Spatial transcriptomics is advancing molecular biology by providing high-resolution insights into gene expression within the spatial context of tissues. This context is essential for identifying spatial domains, enabling the understanding of micro-environment organizations and their implications for tissue function and disease progression. To improve current model limitations on multiple slides, we have designed Novae (https://github.com/MICS-Lab/novae), a graph-based foundation model that extracts representations of cells within their spatial contexts. Our model was trained on a large dataset of nearly 30 million cells across 18 tissues, allowing Novae to perform zero-shot domain inference across multiple gene panels, tissues, and technologies. Unlike other models, it also natively corrects batch effects and constructs a nested hierarchy of spatial domains. Furthermore, Novae supports various downstream tasks, including spatially variable gene or pathway analysis and spatial domain trajectory analysis. Overall, Novae provides a robust and versatile tool for advancing spatial transcriptomics and its applications in biomedical research.                    </p>
                    <div class="publication-links">
                        <a href="https://www.biorxiv.org/content/biorxiv/early/2024/09/13/2024.09.09.612009.full.pdf" class="publication-link">Read Preprint</a>
                        <a href="https://github.com/MICS-Lab/novae" class="publication-link">Supplementary Materials</a>
                    </div>
                </div>
                <img src="../assets/images/research/novae_overview-1.png" 
                        alt="Novae" 
                        class="publication-image">
            </article>

            <!-- Publication 3 -->
            <article class="publication-card" data-type="preprint">
                <div class="publication-content">
                    <span class="publication-year">2024</span>
                    <h2 class="publication-title">
                        Multimodal CustOmics: A Unified and Interpretable Multi-Task Deep Learning Framework for Multimodal Integrative Data Analysis in Oncology
                    </h2>
                    <p class="publication-authors">
                        <span class="publication-highlight">Hakim Benkirane</span>, 
                        Maria Vakalopoulou, David Planchard, Julien Adam, Ken Olaussen, Stefan Michiels, Paul-Henry Cournède
                    </p>
                    <p class="publication-journal">
                        Preprint on bioRxiv
                    </p>
                    <p class="publication-abstract">
                        Characterizing cancer poses a delicate challenge as it involves deciphering complex biological interactions within the tumor’s microenvironment. Histology images and molecular profiling of tumors are often available in clinical trials and can be leveraged to understand these interactions. However, despite recent advances in representing multimodal data for weakly supervised tasks in the medical domain, numerous challenges persist in achieving a coherent and interpretable fusion of whole slide images and multi-omics data. Each modality operates at distinct biological levels, introducing substantial correlations both between and within data sources. In response to these challenges, we propose a deep-learning-based approach designed to represent multimodal data for precision medicine in a readily interpretable manner. While demonstrating superior performance compared to state-of-the-art methods across multiple test cases, our approach also provides robust results and extracts various scores characterizing the activity of each modality and their interactions at the pathway and gene levels. The strength of our method lies in its capacity to unravel pathway activation through multimodal relationships and extend enrichment analysis to spatial data for supervised tasks. We showcase the efficiency and robustness of its predictive capacity and interpretation scores through an extensive exploration of multiple TCGA datasets and validation cohorts, underscoring its value in advancing our understanding of cancer. The method is publicly available in Github.
                    </p>
                    <div class="publication-links">
                        <a href="https://www.biorxiv.org/content/biorxiv/early/2024/01/23/2024.01.20.576363.full.pdf" class="publication-link">Read Preprint</a>
                        <a href="#" class="publication-link">Supplementary Materials</a>
                    </div>
                </div>
                <img src="../assets/images/research/multimodal_customics_overview.png" 
                     alt="Multimodal CustOmics" 
                     class="publication-image">
            </article>

            <!-- Publication 1 -->
            <article class="publication-card" data-type="journal">
                <div class="publication-content">
                    <span class="publication-year">2023</span>
                    <h2 class="publication-title">
                        CustOmics: A versatile deep-learning based strategy for multi-omics integration
                    </h2>
                    <p class="publication-authors">
                        <span class="publication-highlight">Hakim Benkirane</span>, 
                        Yoann Pradat, Stefan Michiels, Paul-Henry Cournède
                    </p>
                    <p class="publication-journal">
                        PLoS Computational Biology
                    </p>
                    <p class="publication-abstract">
                        The availability of patient cohorts with several types of omics data opens new perspectives for exploring the disease’s underlying biological processes and developing predictive models. 
                        It also comes with new challenges in computational biology in terms of integrating high-dimensional and heterogeneous data in a fashion that captures the interrelationships between multiple genes and their functions. 
                        Deep learning methods offer promising perspectives for integrating multi-omics data. In this paper, we review the existing integration strategies based on autoencoders and propose a new customizable one whose principle relies on a two-phase approach. 
                        In the first phase, we adapt the training to each data source independently before learning cross-modality interactions in the second phase. By taking into account each source’s singularity, we show that this approach succeeds at taking advantage of all the sources more efficiently than other strategies. 
                        Moreover, by adapting our architecture to the computation of Shapley additive explanations, our model can provide interpretable results in a multi-source setting. Using multiple omics sources from different TCGA cohorts, we demonstrate the performance of the proposed method for cancer on test cases for several tasks, such as the classification of tumor types and breast cancer subtypes, as well as survival outcome prediction. 
                        We show through our experiments the great performances of our architecture on seven different datasets with various sizes and provide some interpretations of the results obtained. Our code is available on (https://github.com/HakimBenkirane/CustOmics).
                    </p>
                    <div class="publication-links">
                        <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010921" class="publication-link">Read Paper</a>
                        <a href="https://github.com/HakimBenkirane/CustOmics" class="publication-link">View Code</a>
                    </div>
                </div>
                <img src="../assets/images/research/ClassificationResultsCustOmics.png" 
                     alt="CustOmics" 
                     class="publication-image">
            </article>

            <!-- Publication 2 -->
            <article class="publication-card" data-type="conference">
                <div class="publication-content">
                    <span class="publication-year">2022</span>
                    <h2 class="publication-title">
                        Hyper-AdaC: adaptive clustering-based hypergraph representation of whole slide images for survival analysis
                    </h2>
                    <p class="publication-authors">
                        <span class="publication-highlight">Hakim Benkirane</span>, 
                        Maria Vakalopoulou, Stergios Christodoulidis, Ingrid-Judith Garberis, Stefan Michiels, Paul-Henry Cournède
                    </p>
                    <p class="publication-journal">
                        Machine Learning for Health
                    </p>
                    <p class="publication-abstract">
                        The emergence of deep learning in the medical field has popularized the development of models to predict survival outcomes from histopathology images in precision oncology. Graph-based formalism has opened interesting perspectives for generating informative representations, as they can be context-aware and model local and global topological structures in the tumor’s microenvironment. However, the critical issue in using graph representations lies in their generalizability. They can suffer from overfitting due to their large sizes or high discrepancies between nodes due to random sampling from WSI. In addition, standard graph formulations are limited to pairwise interactions, which can sometimes fail to represent the reality observed in histopathology and hinder the interpretability of those interactions. In this work, we present Hyper-AdaC, an adaptive clustering-based hypergraph representation to model high-order correlations among different regions of the WSIs while being compact enough to help graph neural networks generalize in the case of survival prediction. We evaluate our approach on 5 different public available cancer datasets. Our method outperforms most state-of-the-art graph-based methods for survival prediction with WSIs, creating a more efficient and robust alternative to other graph representations. Moreover, due to our formulation, attention maps are depicted at different resolutions depending on the tissue characteristics of each WSI. The code is available at: https://github. com/HakimBenkirane/Hyper-adaC.
                    </p>
                    <div class="publication-links">
                        <a href="https://proceedings.mlr.press/v193/benkirane22a/benkirane22a.pdf" class="publication-link">Read Paper</a>
                        <a href="https://github. com/HakimBenkirane/Hyper-adaC" class="publication-link">Presentation</a>
                    </div>
                </div>
                <img src="../assets/images/research/Hyper-AdaC.jpg" 
                     alt="Hyper-adaC" 
                     class="publication-image">
            </article>




        </section>
    </main>

    <footer>
        <div class="footer-content">
            <div class="footer-main">
                <div class="footer-logo">Hakim Benkirane</div>
                <div class="footer-contact-info">
                    <p>Laboratory of mathematics & Computer Science</p>
                    <p>CentraleSupélec</p>
                    <p>Email: hakim.benkirane@centralesupelec.fr</p>
                    <p>Office: Bouygues Building, SB1XX</p>
                </div>
                <div class="footer-social">
                    <!-- Google Scholar -->
                    <a href="https://scholar.google.com/citations?user=Q0RHPwcAAAAJ&hl=fr" class="social-icon-link" title="Google Scholar">
                        <svg viewBox="0 0 24 24">
                            <path d="M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-24L0 9.5l4.838 3.94A8 8 0 0 1 12 9a8 8 0 0 1 7.162 4.44L24 9.5z"/>
                        </svg>
                    </a>
                    <!-- GitHub -->
                    <a href="https://github.com/HakimBenkirane" class="social-icon-link" title="GitHub">
                        <svg viewBox="0 0 24 24">
                            <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0 0 24 12c0-6.63-5.37-12-12-12z"/>
                        </svg>
                    </a>
                    <!-- LinkedIn -->
                    <a href="https://www.linkedin.com/in/hakim-benkirane-001164166/" class="social-icon-link" title="LinkedIn">
                        <svg viewBox="0 0 24 24">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                        </svg>
                    </a>
                    <!-- ORCID -->
                    <a href="https://orcid.org/0000-0002-1039-3878" class="social-icon-link" title="ORCID">
                        <svg viewBox="0 0 24 24">
                            <path d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.713 0 5.156 2.072 5.156 5.041 0 2.625-1.291 5-4.969 5h-4.087V7.416zm1.444 1.303v7.444h2.525c3.197 0 3.713-2.063 3.713-3.713 0-2.072-.975-3.731-3.797-3.731h-2.441z"/>
                        </svg>
                    </a>
                </div>
            </div>
            <div class="footer-section">
                <h4>Quick Links</h4>
                <div class="footer-links">
                    <a href="research.html">Research</a>
                    <a href="teaching.html">Teaching</a>
                    <a href="talks.html">Talks</a>
                    <a href="publications.html">Publications</a>
                    <a href="positions.html">Positions</a>
                </div>
            </div>
            <div class="footer-section">
                <h4>Resources</h4>
                <div class="footer-links">
                    <a href="../assets/docs/CV_Developer-2.pdf">CV</a>
                    <a href="#">Research Statement</a>
                    <a href="https://mics.centralesupelec.fr">Lab Website</a>
                </div>
            </div>
        </div>
    </footer>
</body>

<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Get all filter buttons and publications
        const filterButtons = document.querySelectorAll('.filter-button');
        const publications = document.querySelectorAll('.publication-card');
    
        // Add click event listener to each filter button
        filterButtons.forEach(button => {
            button.addEventListener('click', () => {
                // Remove active class from all buttons
                filterButtons.forEach(btn => btn.classList.remove('active'));
                
                // Add active class to clicked button
                button.classList.add('active');
                
                // Get the filter value from the data-filter attribute
                const filterValue = button.getAttribute('data-filter');
                
                // Filter publications
                publications.forEach(pub => {
                    if (filterValue === 'all') {
                        pub.style.display = 'grid';
                    } else {
                        pub.style.display = pub.getAttribute('data-type') === filterValue ? 'grid' : 'none';
                    }
                });
            });
        });
    });
    </script>
</html>